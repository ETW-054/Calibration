{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290c4d1e-1627-4b68-ad79-808459b7deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import time\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from utils.MovingAverager import *\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e2a4b45-2556-4ce3-8f12-115673853be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_traj = np.load(f'./training_traj_0.6.npy')\n",
    "training_traj = np.load(f'./all_user_match_data.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b65a27-2e79-47c4-9b4a-a1d3a159c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pocket', 'swing', 'front_pocket', 'horizontal', 'target'}\n"
     ]
    }
   ],
   "source": [
    "train_data = training_traj.item()\n",
    "pose_set = set()\n",
    "for user_name in train_data.keys():\n",
    "    for path_name in train_data[user_name].keys():\n",
    "        for posture_name in train_data[user_name][path_name].keys():\n",
    "            pose_set.add(posture_name)\n",
    "print(pose_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98af7b7f-0faf-4979-8e1d-716903441ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "posture_data = defaultdict(list)\n",
    "train_data = training_traj.item()\n",
    "for user_name in train_data.keys():\n",
    "    for path_name in train_data[user_name].keys():\n",
    "        for posture_name in train_data[user_name][path_name].keys():\n",
    "            data = train_data[user_name][path_name][posture_name]\n",
    "            pos = (data[:, [0, 1]] + np.array((1, 1))) * 0.6\n",
    "            imu = data[:, [3, 4, 5, 6, 7, 8, 9, 10, 11]]\n",
    "            mag = data[:, [12, 13, 14, 15]]\n",
    "\n",
    "            pos_mag = np.concatenate((pos, imu, mag), axis=-1)\n",
    "            posture_data[posture_name].append(pos_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df99560-779e-49a1-9809-07142cb30e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['front_pocket', 'horizontal', 'pocket', 'swing', 'target'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posture_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "353011af-7111-4c92-868c-b75b29114c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_traj(trajs, length=20):\n",
    "    sp_traj = []\n",
    "    for traj in trajs:\n",
    "        for i in range(len(traj) - length + 1):\n",
    "            sp_traj.append(traj[i:i+length])\n",
    "    return np.array(sp_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69bb9c88-a70b-4272-b572-95ea802a5f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((674, 20, 15), (310, 20, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_training_traj = split_traj(posture_data['horizontal'])\n",
    "prep_valid_traj = split_traj(validation_traj)\n",
    "\n",
    "prep_training_traj.shape, prep_valid_traj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a581b9d5-6dc1-4bda-8f23-70bbb5e9afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e7654e-1e9b-4623-8c9c-9ed52bd6d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, data, coords_only=False):\n",
    "\n",
    "        self.data = data\n",
    "        self.coords_only = coords_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.coords_only:\n",
    "            full_data = self.data[idx]  # [20, 2]\n",
    "            coords = full_data[:, :2]\n",
    "            mag = full_data[:, 2:]\n",
    "            return coords, mag\n",
    "        else:\n",
    "            full_data = self.data[idx]  # [20, 11]\n",
    "            coords = full_data[:, :2]  # 提取前兩列為座標\n",
    "            imu_data = full_data[:, 2:11]  # 提取剩下的作為IMU數據\n",
    "            mag = full_data[:, 11:]\n",
    "            return coords, imu_data, mag\n",
    "\n",
    "\n",
    "train_data = [torch.from_numpy(sample).float() for sample in prep_training_traj]\n",
    "impl_data = [torch.from_numpy(sample).float() for sample in prep_valid_traj]\n",
    "\n",
    "# 創建數據集對象\n",
    "train_dataset = IMUDataset(train_data)\n",
    "impl_dataset = IMUDataset(impl_data, coords_only=True)\n",
    "\n",
    "# 創建DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "impl_loader = DataLoader(impl_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e8eae87-ac83-4152-9907-75d94d875a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62c72394-8ff2-40fb-aced-2c86b432cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=2, hidden_size=16, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=16, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=64, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.batchnorm = nn.BatchNorm1d(128)\n",
    "        self.fc = nn.Linear(128, 9)  # 假设输出3个IMU读数\n",
    "\n",
    "    def forward(self, coords):\n",
    "        # 首先，通过样式映射器处理坐标\n",
    "        # 通过生成器主体LSTM处理结合后的输入\n",
    "        output, (h1, c1) = self.lstm1(coords)  # 捕获第一层的隐藏状态和单元状态\n",
    "        output, (h2, c2) = self.lstm2(output)  # 使用第一层的状态作为第二层的初始状态\n",
    "        output, (h3, c3) = self.lstm3(output)\n",
    "        output = self.batchnorm(output.transpose(1, 2)).transpose(1, 2)\n",
    "        imu_data = self.fc(output)\n",
    "        return imu_data\n",
    "\n",
    "# 鉴别器定义保持不变\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=9, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, imu_data):\n",
    "        _, (hidden, _) = self.lstm(imu_data)\n",
    "        output = self.fc(hidden.squeeze(0))\n",
    "        return self.sigmoid(output)\n",
    "\n",
    "# 使用单个模型实例和相同的训练流程\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d027c7a4-d0a9-4177-be9b-60eab3181e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_loss(critic, real_data, fake_data, conditions):\n",
    "    real_scores = critic(real_data, conditions)\n",
    "    fake_scores = critic(fake_data, conditions)\n",
    "    return fake_scores.mean() - real_scores.mean()\n",
    "\n",
    "def generator_loss(critic, fake_data, conditions):\n",
    "    fake_scores = critic(fake_data, conditions)\n",
    "    return -fake_scores.mean()\n",
    "\n",
    "def compute_gradient_penalty(critic, real_data, fake_data, conditions, device):\n",
    "    alpha = torch.rand(real_data.size(0), 1, device=device)\n",
    "    alpha = alpha.expand(real_data.size())\n",
    "    interpolates = alpha * real_data + (1 - alpha) * fake_data\n",
    "    interpolates = interpolates.requires_grad_(True)\n",
    "    conditions = conditions.requires_grad_(True)\n",
    "    d_interpolates = critic(interpolates, conditions)\n",
    "    gradients = torch.autograd.grad(outputs=d_interpolates, inputs=[interpolates, conditions],\n",
    "                                    grad_outputs=torch.ones(d_interpolates.size(), device=device),\n",
    "                                    create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d32e07e5-5e9c-4860-9a84-71e7d71f0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_G = []\n",
    "losses_D = []\n",
    "\n",
    "def evaluate_generator(generator, discriminator, data_loader):\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for coords, _ in data_loader:\n",
    "            coords = coords.to(device)\n",
    "            fake_imu_data = generator(coords)\n",
    "            outputs = discriminator(fake_imu_data).view(-1)\n",
    "            predicted = outputs.round()  # 假设阈值为0.5\n",
    "            total += coords.size(0)\n",
    "            correct += (predicted == 0).sum().item()  # 假设假数据标签为0\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6bde97b-5ba1-45b3-97ec-ab660cb4d1f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m output_real \u001b[38;5;241m=\u001b[39m discriminator(real_imu_data)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m loss_D_real \u001b[38;5;241m=\u001b[39m criterion(output_real, label_real)\n\u001b[0;32m---> 32\u001b[0m fake_imu_data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m output_fake \u001b[38;5;241m=\u001b[39m discriminator(fake_imu_data\u001b[38;5;241m.\u001b[39mdetach())\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m loss_D_fake \u001b[38;5;241m=\u001b[39m criterion(output_fake, label_fake)\n",
      "File \u001b[0;32m~/miniconda3/envs/mag39/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, coords)\u001b[0m\n\u001b[1;32m     13\u001b[0m output, (h1, c1) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm1(coords)  \u001b[38;5;66;03m# 捕获第一层的隐藏状态和单元状态\u001b[39;00m\n\u001b[1;32m     14\u001b[0m output, (h2, c2) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm2(output)  \u001b[38;5;66;03m# 使用第一层的状态作为第二层的初始状态\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m output, (h3, c3) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm3\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchnorm(output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     17\u001b[0m imu_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/mag39/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/mag39/lib/python3.9/site-packages/torch/nn/modules/rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    762\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    765\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "File \u001b[0;32m~/miniconda3/envs/mag39/lib/python3.9/site-packages/torch/_VF.py:25\u001b[0m, in \u001b[0;36mVFModule.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28msuper\u001b[39m(VFModule, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_VariableFunctions\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf, attr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 设置优化器\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.00005, betas=(0.5, 0.9))\n",
    "# 损失函数\n",
    "criterion = nn.BCELoss()\n",
    "accuracy = []\n",
    "# 训练参数\n",
    "num_epochs = 10000\n",
    "real_label = 0.9\n",
    "fake_label = 0.1\n",
    "\n",
    "# 训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    G_losses = []\n",
    "    D_losses_r = []\n",
    "    D_losses_f = []\n",
    "    D_losses = []\n",
    "    for i, (coords, real_imu_data, _) in enumerate(train_loader):\n",
    "        coords, real_imu_data = coords.to(device), real_imu_data.to(device)\n",
    "        batch_size = coords.size(0)\n",
    "        label_real = torch.full((batch_size,), real_label, dtype=torch.float, device=coords.device)\n",
    "        label_fake = torch.full((batch_size,), fake_label, dtype=torch.float, device=coords.device)\n",
    "        \n",
    "        # 训练鉴别器\n",
    "        discriminator.zero_grad()\n",
    "        output_real = discriminator(real_imu_data).view(-1)\n",
    "        loss_D_real = criterion(output_real, label_real)\n",
    "\n",
    "        fake_imu_data = generator(coords)\n",
    "        output_fake = discriminator(fake_imu_data.detach()).view(-1)\n",
    "        loss_D_fake = criterion(output_fake, label_fake)\n",
    "        loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "        loss_D.backward()\n",
    "        if epoch % 5 == 0:\n",
    "            optimizer_D.step()\n",
    "\n",
    "        # 训练生成器\n",
    "        generator.zero_grad()\n",
    "        output_fake = discriminator(fake_imu_data).view(-1)\n",
    "        loss_G = criterion(output_fake, label_real)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        G_losses.append(loss_G.item())\n",
    "        D_losses_r.append(loss_D_real.item())\n",
    "        D_losses_f.append(loss_D_fake.item())\n",
    "        D_losses.append(loss_D.item())\n",
    "\n",
    "    # 每个epoch结束时评估\n",
    "    G_loss, D_loss = np.mean(G_losses), np.mean(D_losses)\n",
    "    D_loss_r, D_loss_f = np.mean(D_losses_r), np.mean(D_losses_f)\n",
    "    losses_G.append(G_loss)\n",
    "    losses_D.append(D_loss)\n",
    "    clear_output(wait=True)\n",
    "    accuracy.append(evaluate_generator(generator, discriminator, impl_loader))\n",
    "    if (epoch + 1) % 10 == 0: \n",
    "        print(f'Epoch {epoch+1:>5d}: Generative loss: {G_loss:>6.3f}, Discrimination loss: {D_loss_r:>6.3f} {D_loss_f:>6.3f}, implement acc: {accuracy[-1]:>6.3f}%')\n",
    "\n",
    "        # 绘制损失曲线\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(losses_G, label='Generator Loss')\n",
    "        plt.plot(losses_D, label='Discriminator Loss')\n",
    "        plt.title('Training Losses')\n",
    "        plt.xlabel('Epoch Number')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(accuracy, label='Impl Accuracy', color='green')\n",
    "        plt.title('Discriminator Accuracy')\n",
    "        plt.xlabel('Epoch Number')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.xlim(max(0, epoch - 100), epoch)\n",
    "        plt.ylim(-3, 103)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4119359-5cee-4470-b29c-7a5e2d63508e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mag39",
   "language": "python",
   "name": "mag39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
