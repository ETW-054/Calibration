{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a92978-52d9-4cc8-b309-2a8874549ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c01a44-c290-4f08-8df4-97acc58764bf",
   "metadata": {},
   "source": [
    "# 解壓縮資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34a0f5a-04f9-4bfb-9154-2001904235c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_data(path):\n",
    "    for folder, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('zip'):\n",
    "                file_path = os.path.join(folder, file)\n",
    "                print(file_path)\n",
    "\n",
    "                sotre_path = os.path.join(folder, file.rsplit('.')[0])\n",
    "                # 開啟 ZIP 壓縮檔 \n",
    "                with zipfile.ZipFile(file_path, 'r') as zf:\n",
    "                    # 解壓縮所有檔案至 /my/folder 目錄\n",
    "                    zf.extractall(path=sotre_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cecf48e8-21b8-46cd-a24d-6d79e9857780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip_data('./swing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986b396b-062a-4ebb-b6a1-1de47dbbb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv(path):\n",
    "    acc_df = pd.read_csv(os.path.join(path, 'Accelerometer.csv'), delimiter=',')\n",
    "    gyo_df = pd.read_csv(os.path.join(path, 'Gyroscope.csv'), delimiter=',')\n",
    "    linacc_df = pd.read_csv(os.path.join(path, 'Linear Accelerometer.csv'), delimiter=',')\n",
    "    mag_df = pd.read_csv(os.path.join(path, 'Magnetometer.csv'), delimiter=',')\n",
    "    device_df = pd.read_csv(os.path.join(path, 'meta', 'device.csv'), delimiter=',')\n",
    "    time_df = pd.read_csv(os.path.join(path, 'meta', 'time.csv'), delimiter=',')\n",
    "    \n",
    "    acc_df.to_csv(os.path.join(path, 'Accelerometer.csv'), index=False, sep=';')\n",
    "    gyo_df.to_csv(os.path.join(path, 'Gyroscope.csv'), index=False, sep=';')\n",
    "    linacc_df.to_csv(os.path.join(path, 'Linear Accelerometer.csv'), index=False, sep=';')\n",
    "    mag_df.to_csv(os.path.join(path, 'Magnetometer.csv'), index=False, sep=';')\n",
    "    device_df.to_csv(os.path.join(path, 'meta', 'device.csv'), index=False, sep=';')\n",
    "    time_df.to_csv(os.path.join(path, 'meta', 'time.csv'), index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a400be-465b-46d6-8920-99424db47df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_csv('./pocket/202301101952/target')\n",
    "# convert_csv('./pocket/202301101952/source')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d0f88-db27-4381-bfa6-8a7f86930454",
   "metadata": {},
   "source": [
    "# 讀檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5f5c14-bd7c-4fb4-99c0-0a0cb769baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_data(df):\n",
    "    new_names = ['acc_times', 'acc_x', 'acc_y', 'acc_z', 'gyo_times', 'gyo_x', 'gyo_y', 'gyo_z', 'lin_acc_times', 'lin_acc_x', 'lin_acc_y', 'lin_acc_z', 'mag_times', 'mag_x', 'mag_y', 'mag_z']\n",
    "    df.columns = new_names\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def load_original_data(path):\n",
    "    acc_df = pd.read_csv(os.path.join(path, 'Accelerometer.csv'), delimiter=';')\n",
    "    gyo_df = pd.read_csv(os.path.join(path, 'Gyroscope.csv'), delimiter=';')\n",
    "    linacc_df = pd.read_csv(os.path.join(path, 'Linear Accelerometer.csv'), delimiter=';')\n",
    "    mag_df = pd.read_csv(os.path.join(path, 'Magnetometer.csv'), delimiter=';')\n",
    "    \n",
    "    total_df = pd.concat([acc_df, gyo_df, linacc_df, mag_df], axis=1)\n",
    "    total_df = rename_data(total_df)\n",
    "    \n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50962f15-f38a-429a-b00a-2adf9a6eb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound_range(df):\n",
    "    start = datapoint_per_second * 35\n",
    "    end = len(df) - datapoint_per_second * 20\n",
    "    \n",
    "    return df.iloc[start:end]\n",
    "\n",
    "\n",
    "def split_segments(df, duration=5):\n",
    "    length = datapoint_per_second * duration\n",
    "    len_of_segs = int(np.floor(len(df) / length))\n",
    "    \n",
    "    segments = []\n",
    "    for i in range(len_of_segs):\n",
    "        segments.append(df.iloc[int(i * length):int((i + 1) * length)].to_numpy())\n",
    "        \n",
    "    return segments\n",
    "\n",
    "\n",
    "def select_data(df):\n",
    "    return df[['acc_x', 'acc_y', 'acc_z', 'gyo_x', 'gyo_y', 'gyo_z', 'lin_acc_x', 'lin_acc_y', 'lin_acc_z', 'mag_x', 'mag_y', 'mag_z']]\n",
    "\n",
    "\n",
    "def preprocess_data(df, duration):\n",
    "    pre_df = bound_range(df)\n",
    "    pre_df = select_data(pre_df)\n",
    "    segs = split_segments(pre_df, duration)\n",
    "    \n",
    "    return segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e99a24c-4c63-4e78-ae26-446adf71d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = load_original_data('./front_pocket/202302071724/source')\n",
    "# segs = preprocess_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57b7b75-a898-49d3-8b69-a7ac8fe74114",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint_per_second = 20\n",
    "duration = 2\n",
    "classes = {'target': 0, 'front_pocket': 1, 'pocket': 2, 'swing': 3}\n",
    "\n",
    "def device_version(path):\n",
    "    device_df = pd.read_csv(os.path.join(path, 'meta/device.csv'), delimiter=';', index_col=0)\n",
    "    version = device_df.loc['deviceRelease'].value\n",
    "    \n",
    "    return version\n",
    "\n",
    "def load_pair_data(root_folder, class_num):\n",
    "    pair_data = []\n",
    "\n",
    "    for folder in os.listdir(root_folder):\n",
    "        if folder.startswith('.'):\n",
    "            continue\n",
    "\n",
    "        folder_path = os.path.join(root_folder, folder)\n",
    "        source_path = os.path.join(folder_path, 'source')\n",
    "        target_path = os.path.join(folder_path, 'target')\n",
    "        \n",
    "        print(folder_path)\n",
    "        \n",
    "        #########################\n",
    "        ##### check devices #####\n",
    "        #########################\n",
    "        while True:\n",
    "            source_version = device_version(source_path)\n",
    "            target_version = device_version(target_path)\n",
    "            \n",
    "            print(source_path, target_path)\n",
    "            \n",
    "            if source_version[:2] == '15' and target_version[:2] == '16':\n",
    "                break\n",
    "            elif source_version[:2] == '16' and target_version[:2] == '15':\n",
    "                source_path = os.path.join(folder_path, 'target')\n",
    "                target_path = os.path.join(folder_path, 'source')\n",
    "                print('--- GG ---')\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        ####################################\n",
    "        ##### load and preprocess data #####\n",
    "        ####################################\n",
    "        source_segs = preprocess_data(load_original_data(source_path), duration)\n",
    "        target_segs = preprocess_data(load_original_data(target_path), duration)\n",
    "\n",
    "        idx = min(len(source_segs), len(target_segs))\n",
    "        source_tags = [class_num] * idx\n",
    "        target_tags = [0] * idx\n",
    "\n",
    "        pair_data.extend(zip(source_segs[:idx], source_tags, target_segs[:idx], target_tags))\n",
    "        \n",
    "    return pair_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34aa6ce4-9bb1-428a-b421-0d086fc4cba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15.4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_version('./front_pocket/202302071523/source')  # source version: 15.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "096e5ad0-4606-4ef4-aa30-ff27a1d21cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16.3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_version('./front_pocket/202302071523/target')  # target version: 16.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee569c5-fda8-44e6-be6b-3aff9efb2445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./front_pocket/202302071628\n",
      "./front_pocket/202302071628/source ./front_pocket/202302071628/target\n",
      "./front_pocket/202302071652\n",
      "./front_pocket/202302071652/source ./front_pocket/202302071652/target\n",
      "./front_pocket/202302071523\n",
      "./front_pocket/202302071523/source ./front_pocket/202302071523/target\n",
      "./front_pocket/202302071531\n",
      "./front_pocket/202302071531/source ./front_pocket/202302071531/target\n",
      "./front_pocket/202302071715\n",
      "./front_pocket/202302071715/source ./front_pocket/202302071715/target\n",
      "./front_pocket/202302071641\n",
      "./front_pocket/202302071641/source ./front_pocket/202302071641/target\n",
      "./front_pocket/202302071541\n",
      "./front_pocket/202302071541/source ./front_pocket/202302071541/target\n",
      "./front_pocket/202302071619\n",
      "./front_pocket/202302071619/source ./front_pocket/202302071619/target\n",
      "./front_pocket/202302071704\n",
      "./front_pocket/202302071704/source ./front_pocket/202302071704/target\n",
      "./front_pocket/202302071724\n",
      "./front_pocket/202302071724/source ./front_pocket/202302071724/target\n",
      "./pocket/202302132108\n",
      "./pocket/202302132108/source ./pocket/202302132108/target\n",
      "./pocket/202302131750\n",
      "./pocket/202302131750/source ./pocket/202302131750/target\n",
      "./pocket/202302131601\n",
      "./pocket/202302131601/source ./pocket/202302131601/target\n",
      "./pocket/202302071606\n",
      "./pocket/202302071606/source ./pocket/202302071606/target\n",
      "./pocket/202302132053\n",
      "./pocket/202302132053/source ./pocket/202302132053/target\n",
      "./pocket/202302122132\n",
      "./pocket/202302122132/source ./pocket/202302122132/target\n",
      "./pocket/202302132116\n",
      "./pocket/202302132116/source ./pocket/202302132116/target\n",
      "./pocket/202302131643\n",
      "./pocket/202302131643/source ./pocket/202302131643/target\n",
      "./pocket/202301101952\n",
      "./pocket/202301101952/source ./pocket/202301101952/target\n",
      "./pocket/202302132101\n",
      "./pocket/202302132101/source ./pocket/202302132101/target\n",
      "./swing/202302142339\n",
      "./swing/202302142339/source ./swing/202302142339/target\n",
      "./swing/202302132131\n",
      "./swing/202302132131/source ./swing/202302132131/target\n",
      "./swing/202302142117\n",
      "./swing/202302142117/source ./swing/202302142117/target\n",
      "./swing/202302132124\n",
      "./swing/202302132124/source ./swing/202302132124/target\n",
      "./swing/202302121947\n",
      "./swing/202302121947/source ./swing/202302121947/target\n",
      "./swing/202302121857\n",
      "./swing/202302121857/source ./swing/202302121857/target\n",
      "./swing/202302142128\n",
      "./swing/202302142128/source ./swing/202302142128/target\n",
      "./swing/202302121920\n",
      "./swing/202302121920/source ./swing/202302121920/target\n",
      "./swing/202302121909\n",
      "./swing/202302121909/source ./swing/202302121909/target\n",
      "./swing/202302142331\n",
      "./swing/202302142331/source ./swing/202302142331/target\n"
     ]
    }
   ],
   "source": [
    "front_pocket_pair_data = load_pair_data('./front_pocket', class_num=1)\n",
    "pocket_pair_data = load_pair_data('./pocket', class_num=2)\n",
    "swing_pair_data = load_pair_data('./swing', class_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73a5c707-8a25-4a06-874d-df286b5599c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1439 1375 1346\n"
     ]
    }
   ],
   "source": [
    "print(len(front_pocket_pair_data), len(pocket_pair_data), len(swing_pair_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46515db-8a56-47e9-8bbe-8283de894d0c",
   "metadata": {},
   "source": [
    "# 建立dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "073af591-76e1-47ec-a306-252417490eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44d14471-de4a-4918-90be-e07462c99c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ada036cd-d67b-4d25-b935-0cdcde61f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, seq_len=100, num_of_classes=2):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Linear(9, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size=16, hidden_size=16, num_layers=2, batch_first=True)\n",
    "#         self.lstm = nn.LSTM(input_size=16, hidden_size=16, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.last = nn.Sequential(\n",
    "            nn.Linear(16, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, num_of_classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.layer0(x)\n",
    "        \n",
    "        hz, _ = self.rnn(h)\n",
    "        \n",
    "        out = self.last(hz)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9366367b-10db-4dd5-972b-eb89ad061ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1, 2, 3]), array([693, 719, 687, 673])),\n",
       " (array([0, 1, 2, 3]), array([2081,  720,  688,  673])))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front_pocket_half = int(len(front_pocket_pair_data) / 2)\n",
    "pocket_half = int(len(pocket_pair_data) / 2)\n",
    "swing_half = int(len(swing_pair_data) / 2)\n",
    "\n",
    "train_data = front_pocket_pair_data[:front_pocket_half] + pocket_pair_data[:pocket_half] + swing_pair_data[:swing_half]\n",
    "valid_data = front_pocket_pair_data[front_pocket_half:] + pocket_pair_data[pocket_half:] + swing_pair_data[:swing_half]\n",
    "\n",
    "# train\n",
    "t_data = np.array([d[0] for d in train_data] + [d[2] for d in train_data[::3]])\n",
    "t_label = [d[1] for d in train_data] + [d[3] for d in train_data[::3]]\n",
    "train_dataset = ClassDataset(\n",
    "                    data = torch.tensor(t_data, dtype=torch.float),\n",
    "                    label = t_label,\n",
    "                )\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# valid\n",
    "v_data = np.array([d[0] for d in valid_data] + [d[2] for d in valid_data])\n",
    "v_label = [d[1] for d in valid_data] + [d[3] for d in valid_data]\n",
    "valid_dataset = ClassDataset(\n",
    "                    data = torch.tensor(v_data, dtype=torch.float),\n",
    "                    label = v_label,\n",
    "                )\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16)\n",
    "\n",
    "np.unique(t_label, return_counts=True), np.unique(v_label, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b88b083b-cc71-47d3-8491-780712b263eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1674672d-763d-47dc-a44c-7e7820893068",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 30\n",
    "num_of_classes = 4\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31e23ee4-8da1-4fc7-bbd9-0b2397de5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRNN(seq_len=int(datapoint_per_second * duration), num_of_classes=num_of_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "ce_loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eba50865-9a85-43cb-8719-61f8868194cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for sequences, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sequences = sequences.to(device)\n",
    "#             labels = labels.to(device)\n",
    "        one_hot = F.one_hot(labels, num_classes=num_of_classes).to(device)\n",
    "\n",
    "        predict_probability = model(sequences[:, :, :9])\n",
    "        _, predict_classes = torch.max(predict_probability, 1)\n",
    "\n",
    "        loss = ce_loss(predict_probability, one_hot)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        #accuracies.append(accuracy_score(labels.cpu().detach().numpy(), predict_classes.cpu().detach().numpy()))\n",
    "    \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cb16192-e16c-4d77-bc8f-7d1b6eff1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in dataloader:\n",
    "            \n",
    "            sequences = sequences.to(device)\n",
    "#             labels = labels.to(device)\n",
    "            one_hot = F.one_hot(labels, num_classes=num_of_classes).to(device)\n",
    "\n",
    "            #############\n",
    "            # generator #\n",
    "            #############\n",
    "            predict_probability = model(sequences[:, :, :9])\n",
    "            _, predict_classes = torch.max(predict_probability, 1)\n",
    "\n",
    "            loss = ce_loss(predict_probability, one_hot)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            #accuracies.append(accuracy_score(labels.cpu().detach().numpy(), predict_classes.cpu().detach().numpy()))\n",
    "    \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5e74f03-1f6e-4245-976b-7ef42b7c366c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000: train loss:  3.319, valid loss:  2.984\n",
      "00001: train loss:  2.982, valid loss:  2.981\n",
      "00002: train loss:  2.981, valid loss:  2.981\n",
      "00003: train loss:  2.981, valid loss:  2.981\n",
      "00004: train loss:  2.981, valid loss:  2.981\n",
      "00005: train loss:  2.981, valid loss:  2.981\n",
      "00006: train loss:  2.981, valid loss:  2.981\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCH):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#####\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 1. 用上半部訓練50epoch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# 2. 隨機用上或下半部訓練Model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# 3. 印出trajectory結果\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#####\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evalute(model, valid_loader)\n\u001b[1;32m     11\u001b[0m     ep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[38], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#             labels = labels.to(device)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         one_hot \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(labels, num_classes\u001b[38;5;241m=\u001b[39mnum_of_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 14\u001b[0m         predict_probability \u001b[38;5;241m=\u001b[39m model(\u001b[43msequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     15\u001b[0m         _, predict_classes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(predict_probability, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m         loss \u001b[38;5;241m=\u001b[39m ce_loss(predict_probability, one_hot)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    #####\n",
    "    # 1. 用上半部訓練50epoch\n",
    "    # 2. 隨機用上或下半部訓練Model\n",
    "    # 3. 印出trajectory結果\n",
    "    #####\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer)\n",
    "    valid_loss = evalute(model, valid_loader)\n",
    "    \n",
    "    ep = str(epoch).zfill(5)\n",
    "\n",
    "    print(f'{ep}: train loss: {train_loss: 2.3f}, valid loss: {valid_loss: 2.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23719eaf-64e5-4011-b6e3-99c822ddf8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_eval(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (sequences, labels) in enumerate(dataloader):\n",
    "            \n",
    "            sequences = sequences.to(device)\n",
    "#             labels = labels.to(device)\n",
    "            one_hot = F.one_hot(labels, num_classes=num_of_classes).to(device).float()\n",
    "\n",
    "            #############\n",
    "            # generator #\n",
    "            #############\n",
    "            predict_probability = model(sequences[:, :, :9])\n",
    "            _, predict_classes = torch.max(predict_probability, 1)\n",
    "            \n",
    "            print(f'{i: >3} predict class: {predict_classes.cpu().detach().numpy()}')\n",
    "            print(f'{\"\": >3}  ground truth: {labels.numpy()}')\n",
    "\n",
    "            loss = ce_loss(predict_probability, one_hot)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            accuracies.append(accuracy_score(labels.cpu().detach().numpy(), predict_classes.cpu().detach().numpy()))\n",
    "            \n",
    "    print(f'loss: {np.mean(losses): 2.3f}, accuracy: {np.mean(accuracies): 2.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c0beb-8280-4a77-a23a-e421405bb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_eval(model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1bea9-59c8-44c6-9423-078f3cefe4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78fab0c5-1510-4d9b-b7d9-349b2d245767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190cb4c-a8b2-42d3-97b8-a33a2703072e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mag39",
   "language": "python",
   "name": "mag39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
